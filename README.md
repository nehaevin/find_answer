# find_answer
учим нейросети находить ответы на вопросы студентов

## Дано
Есть форум ЧаВо, на котором формируется перечень вопросов и ответов. Студенты могут лайкать полезные ответы.
Таким образом можно со временем сформировать список пар "вопрос - полезный ответ". На один вопрос может быть несколько ответов. И наоборот.

## Требуется
Построить pipeline, который позволяет для вновь заданного вопроса находить наиболее релевантные ответы из имеющихся и формировать TOP-3 наиболее подходящих.

## Задача для проектных групп
1. Для списка (из минимум 15) подготовленных преподавателем вопросов на выбранную тематику найти в инете подходящие ответы или самим написать ответ и сформировать *обучающую выборку* - пары "вопрос - ответ". Ответ должен быть содержательным, как минимум один абзац текста (формулы могут быть, но они плохо будут интерпретироваться) и ссылка на статью в инете, откуда взят материал (если взят из инета). 
2. Подготовить тестовую выборку 10 тестовых вопросов - на которые есть уже ответы (переформулированные вопросы из исходной выборки), т.е. как минимум 10 пар "вопрос-ответ" и 5 вопросов, которые близки по тематике, но на которые ответов нет (есть близкие по смыслу заданных вопросов)
3. Подготовить соответствующие словари и сформировать pipeline, на вход которого подается текст вопроса, а на выходе - top-3 наиболее релеватных ответов из списка имеющихся.
4. Оценить точность работы pipeline на имеющихся выборках - на обучающей и на тестовой с метрикой accuracy на TOP-3 и на TOP-1. А также проанализировать работу системы на 5 новых вопросах.

## Модели для построения pipeline
---
**Модель 1. Нулевая** С нуля строим токенизатор и обучаем нейросеть эмбеддить и классифицировать ответы (оценить степень релевантности) на поставленный вопрос. Для более лучшего обучения здесь понадобятся не только пары "вопрос - релевантный ответ", но и "вопрос - нерелеватный ответ" и большая обучающая выборка. 

**Модель 2. Готовая** Берем полностью обученные модели токенизатора (со словарем) и нейросети, которая может эмбеддить тексты, эмбеддим тексты вопроса и ответов, нормируем вектора эмбеддингов и определяем по скалярному произведению (косуинусу угла, коэф. корреляции) наиболее близкие ответы. Можно использовать либо гугловские нейросеть RuBert-tiny либо LabSE (en-ru) либо сбербанковскую ruRoberta. см. например https://habr.com/en/post/562064/, https://huggingface.co/cointegrated. Пример применения LabSE с использованием tf: https://tfhub.dev/google/LaBSE/2

**Модель 3. Комбинированная** Используем предобученные модели токенизатора и нейросети (гугла или сбера) для эмбеддинга текста вопроса, а затем обучаем доп. нейросеть (слой) классифицировать ответы по релевантности. Это лучшая модель, но требует перепостроения и переобучения последнего слоя при добавлении новых ответов. Таким образом, необходимо добавлять еще один pipeline для добавления нового ответа в систему (перестроения классификатора и его дообучения).
